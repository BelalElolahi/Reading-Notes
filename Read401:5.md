# Linked Lists 
## Big O: Analysis of Algorithm Efficiency
Big O(oh) notation is used to describe the efficiency of an algorithm or function. This efficiency is evaluated based on 2 factors:

Running Time (also known as time efficiency / complexity)
The amount of time a function needs to complete.

Memory Space (also known as space efficiency / complexity)
The amount of memory resources a function uses to store data and instructions.

Overview
Big O’s role in algorithm efficiency is to describe the Worst Case of efficiency an algorithm can have in performing it’s job. It specifically looks at the factors mentioned above, which we often refer to as Space and Time. In order to analyze these limiting factors, we should consider 4 Key Areas for analysis:

Input Size

Units of Measurement

Orders of Growth

Best Case, Worst Case, and Average Case 

![](https://www.freecodecamp.org/news/content/images/2021/06/0_cyqWw3UxODl-wqJi.jpg) 


### Orders of Growth
We can describe overall efficiency by using the input size n and measuring the overall Units of Space and Time required for the given input size n. As the value of n grows, the Order of Growth represents the increase in Running Time or Memory Space. 
![](https://www.cpp.edu/~ftang/courses/CS240/lectures/img/alg-tab.jpg)


#### Asymptotic Notations

For each of the cases mentioned above, academics use the following notations in the following table to describe the differing complexities of an algorithm. Also (as mentioned earlier), we are focused more on Big O as an industry standard, but it’s helpful to be aware that there are other ways we can analyze algorithmic efficiencies.

+ Big O(oh): This notation describes the Worst Case for an algorithm. The Order of Growth used represents the upper bounds of Time and Space.

+ Big Omega: This notation describes the Best Case for a given algorithm. The Order of Growth used represents the lower bounds of Time and Space.

+ Big Theta: This notation describes the Average Case. The Order of Growth used represents the tight bound of Time and Space.

We use the term tight since, in order to predict a “typical” input, we need an idea of what makes our function perform better or worse. Tight means that the upper and lower can both be set by this Order of Growth.

##### Review

Big O: The worst case analysis of algorithm efficiency.
Running Time: The amount of time required for an algorithm to complete.
Memory Space: The amount of memory resources required for an algorithm to complete.
Input Size: Represented by the variable n, the total size of values used as parameters in an algorithm.
Big Omega: The best case analysis of algorithm efficiency.
Big Theta: The typical or random case used for analysis of algorithm efficiency.

![](https://images.squarespace-cdn.com/content/v1/5acbdd3a25bf024c12f4c8b4/1599000012698-NJEGM0BCGG5ZKGIWC1GU/Big%2BO%2BNotation%2BSummary%2B%281%29.jpg)
## Linked Lists 
**Linked List** - A data structure that contains nodes that links/points to the next node in the list. 
 
 In computer science, a linked list is a linear collection of data elements whose order is not given by their physical placement in memory. Instead, each element points to the next. It is a data structure consisting of a collection of nodes which together represent a sequence 

 ![](https://res.cloudinary.com/practicaldev/image/fetch/s--XEtVnws7--/c_imagga_scale,f_auto,fl_progressive,h_900,q_auto,w_1600/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/trsu6uhv8j0x1fhzx53a.png)


 #### Why Linked List? 
Arrays can be used to store linear data of similar types, but arrays have the following limitations. 

1) The size of the arrays is fixed: So we must know the upper limit on the number of elements in advance. Also, generally, the allocated memory is equal to the upper limit irrespective of the usage. 

2) Inserting a new element in an array of elements is expensive because the room has to be created for the new elements and to create room existing elements have to be shifted. 
For example, in a system, if we maintain a sorted list of IDs in an array id[]. 

id[] = [1000, 1010, 1050, 2000, 2040]. 

And if we want to insert a new ID 1005, then to maintain the sorted order, we have to move all the elements after 1000 (excluding 1000). 
Deletion is also expensive with arrays until unless some special techniques are used. For example, to delete 1010 in id[], everything after 1010 has to be moved.
![](https://miro.medium.com/max/875/1*cUehR5S18XSoVLaPNfNzlA.jpeg)

Advantages over arrays 

1) Dynamic size 

2) Ease of insertion/deletion
Drawbacks: 

+  Random access is not allowed. We have to access elements sequentially starting from the first node. So we cannot do binary search with linked lists efficiently with its default implementation. Read about it here. 
+  Extra memory space for a pointer is required with each element of the list. 
+  Not cache friendly. Since array elements are contiguous locations, there is locality of reference which is not there in case of linked lists.
![](https://i.stack.imgur.com/0iuuJ.gif)



![](https://i.ytimg.com/vi/-LYGm6d_oRc/maxresdefault.jpg)
Representation: 
A linked list is represented by a pointer to the first node of the linked list. The first node is called the head. If the linked list is empty, then the value of the head is NULL. 
Each node in a list consists of at least two parts: 

1) data 

2) Pointer (Or Reference) to the next node 

In C, we can represent a node using structures. Below is an example of a linked list node with integer data. 
In Java or C#, LinkedList can be represented as a class and a Node as a separate class. The LinkedList class contains a reference of Node class type. 


### Time and Space Complexity
**Time**

Linked lists have most of their benefit when it comes to the insertion and deletion of nodes in the list. Unlike the dynamic array, insertion and deletion at any part of the list takes constant time.

However, unlike dynamic arrays, accessing the data in these nodes takes linear time because of the need to search through the entire list via pointers. It's also important to note that there is no way of optimizing search in linked lists. In the array, we could at least keep the array sorted. However, since we don't know how long the linked list is, there is no way of performing a binary search:

​
Indexing - O(n),
​
  
Insertion - O(1),

Search - O(n).
​
  
Deletion - O(1),
 
**Space**

Linked lists hold two main pieces of information (the value and pointer) per node. This means that the amount of data stored increases linearly with the number of nodes in the list. Therefore, the space complexity of the linked list is linear:

  
Space - O(n) 


​
 .




